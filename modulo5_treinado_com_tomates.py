# -*- coding: utf-8 -*-
"""MODULO5_treinado_com_TOMATES.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uxj40eCgtVJms08bATv1U8zuFMq12vLz
"""

!pip install torch torchvision
!pip install tensorflow
!pip install opencv-python
!pip install matplotlib

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5
!pip install -r requirements.txt

import torch
import cv2
from pathlib import Path
from google.colab.patches import cv2_imshow
import sys
import os
sys.path.append(str(Path('yolov5')))  # Adiciona o repositório YOLOv5 ao caminho

from models.experimental import attempt_load
from utils.general import non_max_suppression
from utils.torch_utils import select_device
from google.colab.patches import cv2_imshow

# Selecionar o dispositivo (CPU ou GPU)
device = select_device('cuda' if torch.cuda.is_available() else 'cpu')

#ocultar
from google.colab import drive
drive.mount('/content/drive')

# Passo 1: Configuração para o treinamento
# O arquivo data.yaml precisa ser configurado com os caminhos e classes do seu dataset.
# Exemplo:
# data_yaml = {
#     'train': '/path/to/dataset/train/images',
#     'val': '/path/to/dataset/val/images',
#     'nc': 2,  # Número de classes
#     'names': ['classe1', 'classe2']  # Nomes das classes
# }
# Salve esse arquivo como "data.yaml" na pasta que contém seu dataset.

# Passo 2: Treinamento do modelo (será executado uma vez para treinar o modelo)
# Você pode rodar o treinamento com o seguinte comando:
!python train.py --img 640 --batch 16 --epochs 10 --data /content/drive/MyDrive/Dataset_Tomate/data.yaml --weights yolov5s.pt --cache
#!python train.py --img 640 --batch 16 --epochs 50 --data /content/drive/MyDrive/Dataset_Tomate/data.yaml --weights yolov5n.pt --cache

# Após o treinamento, o modelo será salvo em `runs/train/exp/weights/best.pt`.

cat runs/train/exp/results.csv

# Passo 3: Carregar o modelo treinado
model = attempt_load('runs/train/exp/weights/best.pt', device=device)
#model = attempt_load('yolov5s.pt', device=device)

# Passo 4: Carregar a imagem para inferência
img_path = os.path.abspath('./../tomate2.jpg')
img = cv2.imread(img_path)

# Verificar se a imagem foi carregada corretamente
if img is None:
    print(f"Erro ao carregar a imagem. Verifique o caminho: {img_path}")
    exit()  # Encerra o código se a imagem não for carregada

# Pré-processamento da imagem: redimensionar para 640x640
img_resized = cv2.resize(img, (640, 640))  # Redimensiona para o tamanho esperado

# Converter a imagem de BGR (OpenCV) para RGB
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

# Convertê-la para um tensor e adicionar uma dimensão extra para o batch size (batch_size=1)
img_tensor = torch.from_numpy(img_rgb).float()

# Adicionar a dimensão do batch size (deve ficar [1, 3, 640, 640])
img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0).to(device)  # Permuta para [3, 640, 640] e adiciona o batch_size

# Normalizar para o intervalo [0, 1]
img_tensor /= 255.0

# Passo 5: Fazer a predição
pred = model(img_tensor)[0]  # O modelo retorna uma lista de predições
pred = non_max_suppression(pred, 0.4, 0.5)  # Aplica a supressão de não-máximos
print(pred)

# Exibir as predições (desenho das caixas delimitadoras)
for det in pred[0]:
    if det is not None and len(det):
        x1, y1, x2, y2, conf, cls = det[:6]
        cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
        cv2.putText(img, f'{model.names[int(cls)]} {conf:.2f}', (int(x1), int(y1)-10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)

# Exibir a imagem com as detecções
print("Detecção YOLOv5")
cv2_imshow(img)
#cv2.waitKey(0)
#cv2.destroyAllWindows()